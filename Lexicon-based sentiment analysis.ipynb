{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2dbe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /Users/dachuanzhang/opt/anaconda3/lib/python3.8/site-packages (0.42.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b208b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6cbe77",
   "metadata": {},
   "source": [
    "# Load sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503be571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/f9/nxp8wrj16mq509ksxvv0krj00000gn/T/jieba.cache\n",
      "Loading model cost 0.440 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "stop_words = open(\"./emotion_dict/stop_words.txt\", encoding=\"utf-8\").readlines()\n",
    "stop_words = [s.strip() for s in stop_words]\n",
    "for sw in stop_words:\n",
    "    jieba.del_word(sw)\n",
    "    \n",
    "def cutword(x):\n",
    "    seg = jieba.cut(x) \n",
    "    new_seg = []\n",
    "    for key in seg:\n",
    "        if not(key.strip() in stop_words) and (len(key.strip()) > 1):\n",
    "            new_seg.append(key)\n",
    "    return new_seg\n",
    "    \n",
    "\n",
    "def cut_sentence(words):\n",
    "    start = 0\n",
    "    i = 0\n",
    "    token = 'meaningless'\n",
    "    sents = []\n",
    "    punt_list = ',.!?;~，。！？；～… '\n",
    "    for word in words:\n",
    "        if word not in punt_list:  \n",
    "            i += 1\n",
    "            token = list(words[start:i+2]).pop()\n",
    "        elif word in punt_list and token in punt_list:  \n",
    "            i += 1\n",
    "            token = list(words[start:i+2]).pop()\n",
    "        else:\n",
    "            sents.append(words[start:i+1])  \n",
    "            start = i + 1\n",
    "            i += 1\n",
    "    if start < len(words): \n",
    "        sents.append(words[start:])\n",
    "        \n",
    "    return sents\n",
    "\n",
    "\n",
    "def read_lines(filename):\n",
    "    fp = open(filename, 'r', encoding=\"utf-8\")\n",
    "    lines = []\n",
    "    for line in fp.readlines():\n",
    "        line = line.strip()\n",
    "        line = line\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def del_stopwords(seg_sent):\n",
    "    stopwords = read_lines(\"./emotion_dict/stop_words.txt\")  \n",
    "    new_sent = []   \n",
    "    for word in seg_sent:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            new_sent.append(word)\n",
    "    return new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8be011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffno', '不', '没', '不要', '难以', '未曾', '无', '非', '莫', '弗', '毋', '未', '否', '别', '无', '不够', '不是', '不曾', '未必', '没有']\n"
     ]
    }
   ],
   "source": [
    "posdict = read_lines(\"./emotion_dict/pos_all_dict.txt\")\n",
    "negdict = read_lines(\"./emotion_dict/neg_all_dict.txt\")\n",
    "\n",
    "mostdict = read_lines('./degree_dict/most.txt')   \n",
    "verydict = read_lines('./degree_dict/very.txt')  \n",
    "moredict = read_lines('./degree_dict/more.txt')  \n",
    "nearlydict = read_lines('./degree_dict/nearly.txt')   \n",
    "barelydict = read_lines('./degree_dict/barely.txt') \n",
    "inversedict = read_lines('./degree_dict/inversion.txt')  \n",
    "\n",
    "print(inversedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55425e11",
   "metadata": {},
   "source": [
    "# Calculate sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21627679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(word, sentiment_value):\n",
    "    if word in mostdict:\n",
    "        sentiment_value *= 2.0\n",
    "        \n",
    "    elif word in verydict:\n",
    "        sentiment_value *= 1.75\n",
    "        \n",
    "    elif word in moredict:\n",
    "        sentiment_value *= 1.5\n",
    "        \n",
    "    elif word in nearlydict:\n",
    "        sentiment_value *= 1\n",
    "        \n",
    "    elif word in barelydict:\n",
    "        sentiment_value *= 0.5\n",
    "        \n",
    "    elif word in inversedict:\n",
    "        sentiment_value *= -1\n",
    "\n",
    "    return sentiment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e85624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_positive_num(poscount, negcount):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    if poscount < 0 and negcount >= 0:\n",
    "        neg_count += negcount - poscount\n",
    "        pos_count = 0\n",
    "        \n",
    "    elif negcount < 0 and poscount >= 0:\n",
    "        pos_count = poscount - negcount\n",
    "        neg_count = 0\n",
    "        \n",
    "    elif poscount < 0 and negcount < 0:\n",
    "        neg_count = -poscount\n",
    "        pos_count = -negcount\n",
    "    else:\n",
    "        pos_count = poscount\n",
    "        neg_count = negcount\n",
    "        \n",
    "    return (pos_count, neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44da9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_review_sentiment_score(content):\n",
    "    single_review_senti_score = []\n",
    "    cuted_review = cut_sentence(content)  \n",
    "\n",
    "    for sent in cuted_review:\n",
    "        seg_sent = cutword(sent)\n",
    "        seg_sent = del_stopwords(seg_sent)[:]\n",
    "\n",
    "        i = 0    \n",
    "        s = 0   \n",
    "        poscount = 0    \n",
    "        negcount = 0\n",
    "\n",
    "        for word in seg_sent:   \n",
    "            if word in posdict: \n",
    "                poscount += 1  \n",
    "                for w in seg_sent[s:i]:\n",
    "                    poscount = match(w, poscount)\n",
    "                s = i + 1  \n",
    "\n",
    "            elif word in negdict: \n",
    "                negcount += 1\n",
    "                for w in seg_sent[s:i]:\n",
    "                    negcount = match(w, negcount)\n",
    "                s = i + 1\n",
    "\n",
    "            elif word == \"！\" or word == \"!\":\n",
    "                for w2 in seg_sent[::-1]:  \n",
    "                    if w2 in posdict:\n",
    "                        poscount += 2\n",
    "                        break\n",
    "                    elif w2 in negdict:\n",
    "                        negcount += 2\n",
    "                        break\n",
    "            i += 1\n",
    "        single_review_senti_score.append(transform_to_positive_num(poscount, negcount))   \n",
    "    pos_result, neg_result = 0, 0\n",
    "    \n",
    "    for res1, res2 in single_review_senti_score:  \n",
    "        pos_result += res1\n",
    "        neg_result += res2\n",
    "        \n",
    "    result = pos_result - neg_result  \n",
    "    result = round(result, 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa77cdd",
   "metadata": {},
   "source": [
    "# Load public opinion and conduct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a8e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_score(file_name):\n",
    "    fp_test = open(file_name, 'r')\n",
    "    \n",
    "    contents = []\n",
    "    for content in fp_test.readlines():\n",
    "        content = content.strip()\n",
    "        contents.append(content)\n",
    "    \n",
    "    results = []\n",
    "    for content in contents:\n",
    "        score = single_review_sentiment_score(content)  \n",
    "        results.append((score, content))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "323b01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(file_name, results):\n",
    "    fp_result = open(file_name, 'w')\n",
    "    \n",
    "    fp_result.write(\"Public opinion\")\n",
    "    fp_result.write('\\t')\n",
    "    fp_result.write(\"Sentiment score\")\n",
    "    fp_result.write('\\n')\n",
    "    \n",
    "    for result in results:\n",
    "        fp_result.write(result[1])\n",
    "        fp_result.write('\\t')\n",
    "        fp_result.write(str(result[0]))\n",
    "        fp_result.write('\\n')\n",
    "        \n",
    "    fp_result.close()\n",
    "\n",
    "    \n",
    "def summary(results):\n",
    "    pos_number, neg_number = 0, 0\n",
    "    pos_mean, neg_mean = 0, 0\n",
    "    pos_variance, neg_variance, var_ratio = 0, 0, 0\n",
    "    pos_list, neg_list, total_list = [], [], []\n",
    "    \n",
    "    for result in results:\n",
    "        total_list.append(result[0])\n",
    "        if result[0] >= 0:\n",
    "            pos_list.append(result[0])   \n",
    "        else:\n",
    "            neg_list.append(result[0])   \n",
    "\n",
    "    pos_number = len(pos_list)\n",
    "    neg_number = len(neg_list)\n",
    "    \n",
    "    total_number = pos_number + neg_number\n",
    "    pos_number_ratio = round(float(pos_number)/float(total_number), 2)\n",
    "    neg_number_ratio = round(float(neg_number)/float(total_number), 2)\n",
    "    text_pos_number = \"Number of positive smaples: \" + str(pos_number) + \" Percentage: \" + str(pos_number_ratio*100)\n",
    "    text_neg_number = \"Number of negative smaples: \" + str(neg_number) + \" Percentage: \" + str(neg_number_ratio*100)\n",
    "    \n",
    "    pos_array = np.array(pos_list)\n",
    "    neg_array = np.array(neg_list)   \n",
    "    total_array = np.array(total_list)\n",
    "    pos_mean = pos_array.mean()\n",
    "    neg_mean = neg_array.mean()\n",
    "    total_mean = total_array.mean()   \n",
    "        \n",
    "    pos_variance = pos_array.var(axis=0)\n",
    "    neg_variance = neg_array.var(axis=0)\n",
    "    total_variance = total_array.var(axis=0)\n",
    "\n",
    "        \n",
    "    result_dict = {}\n",
    "    result_dict['pos_number'] = pos_number   \n",
    "    result_dict['neg_number'] = neg_number  \n",
    "    \n",
    "    result_dict['pos_mean'] = round(pos_mean, 1)  \n",
    "    result_dict['neg_mean'] = round(neg_mean, 1)  \n",
    "    result_dict['total_mean'] = round(total_mean, 1) \n",
    "    \n",
    "    result_dict['pos_variance'] = round(pos_variance, 1)  \n",
    "    result_dict['neg_variance'] = round(neg_variance, 1)  \n",
    "    result_dict['total_variance'] = round(total_variance, 1)\n",
    "    \n",
    "    result_dict['text_pos_number'] = text_pos_number   \n",
    "    result_dict['text_neg_number'] = text_neg_number\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450c936f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_number  |  2\n",
      "neg_number  |  3\n",
      "pos_mean  |  3.0\n",
      "neg_mean  |  -1.3\n",
      "total_mean  |  0.4\n",
      "pos_variance  |  9.0\n",
      "neg_variance  |  0.2\n",
      "total_variance  |  8.2\n",
      "text_pos_number  |  Number of positive smaples: 2 Percentage: 40.0\n",
      "text_neg_number  |  Number of negative smaples: 3 Percentage: 60.0\n"
     ]
    }
   ],
   "source": [
    "results = run_score(\"./data/test_public_opinion.txt\")\n",
    "write_results(\"./data/predicted_results.txt\", results)\n",
    "result_dict = summary(results)   \n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    print(key, \" | \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be3ff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Public opinion</th>\n",
       "      <th>Sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>【#老顾客投诉被店家说手法娴熟# 消费者认为对方在诽谤】2月5号，张先生点了一份麻辣香锅外卖...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>『县政府副县长王海娟到夏蔚镇检查食品安全工作』</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>点了个肯德基嫩牛五方 它竟然是臭的？你敢信！我吃了几口不对劲直接吐了！国内食品安全我想说，在...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2月10日，河南省市场监管局召开全省落实食品安全属地管理和企业主体“两个责任”工作推进会议。...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>民以食为天，食以安为先。食品安全的重要性实在不必多说，但如此重要的领域，却仍然年年都能被媒体...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Public opinion  Sentiment score\n",
       "0  【#老顾客投诉被店家说手法娴熟# 消费者认为对方在诽谤】2月5号，张先生点了一份麻辣香锅外卖...               -1\n",
       "1                            『县政府副县长王海娟到夏蔚镇检查食品安全工作』                0\n",
       "2  点了个肯德基嫩牛五方 它竟然是臭的？你敢信！我吃了几口不对劲直接吐了！国内食品安全我想说，在...               -1\n",
       "3  2月10日，河南省市场监管局召开全省落实食品安全属地管理和企业主体“两个责任”工作推进会议。...                6\n",
       "4  民以食为天，食以安为先。食品安全的重要性实在不必多说，但如此重要的领域，却仍然年年都能被媒体...               -2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/predicted_results.txt\", sep=\"\\t\",)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
